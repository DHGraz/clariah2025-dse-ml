{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6778d16863b961a9",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "<!-- Title Slide -->\n",
    "\n",
    "<table>\n",
    "<tr>\n",
    "<td style=\"width:40%; vertical-align:middle; text-align:center;\">\n",
    "  <img src=\"https://maartengr.github.io/BERTopic/logo.png\" alt=\"Topic Modeling Illustration\" width=\"300\"/>\n",
    "</td>\n",
    "<td style=\"width:60%; vertical-align:middle; padding-left:20px;\">\n",
    "\n",
    "  # üìù Topic Modeling with BERTopic\n",
    "  ## Session: Text Embeddings\n",
    "\n",
    "  <br>\n",
    "  <br>\n",
    "  <span style=\"font-size:1.2em; color:gray;\">\n",
    "    Michael Jantscher ¬∑ TU Graz ¬∑ Know Center Research GmbH\n",
    "  </span>\n",
    "\n",
    "</td>\n",
    "</tr>\n",
    "</table>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1979fd664ce57d1",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "# üëã Michael Jantscher\n",
    "\n",
    "<img src=\"https://dhgraz.github.io/clariah2025-dse-ml/images/artists/profil_michael.jpg\" alt=\"Michael Jantscher\" width=\"250\"/>\n",
    "\n",
    "**PhD Student** - TU Graz <br>\n",
    "**Researcher** - Know Center Research GmbH\n",
    "\n",
    "---\n",
    "\n",
    "### üß† Focus Areas\n",
    "- Natural Language Processing (NLP) in medical & clinical domains\n",
    "- Causal reasoning in healthcare and (neuro)radiology\n",
    "- Agentic AI systems for decision support and research workflows\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "987d813d562d2c91",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "# What is a Text Embedding Vector - Formal Definition?\n",
    "* Numerical representation of text (words, sentences or documents) in a multi-dimensional space\n",
    "* Captures meaning and context"
   ]
  },
  {
   "cell_type": "code",
   "id": "6295062dc4488f9b",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": [],
    "ExecuteTime": {
     "end_time": "2025-09-04T11:53:23.870381Z",
     "start_time": "2025-09-04T11:53:20.504621Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "np.set_printoptions(precision=3, suppress=True, edgeitems=10)\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "st_model_small = SentenceTransformer('all-minilm-l6-v2')\n",
    "\n",
    "sample_string = \"I really like this lecture!\"\n",
    "\n",
    "sample_string_embedding = st_model_small.encode(sample_string)\n",
    "df = pd.DataFrame({\n",
    "    \"text\": [sample_string],\n",
    "    \"embedding\": [sample_string_embedding]\n",
    "})\n",
    "df"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                          text  \\\n",
       "0  I really like this lecture!   \n",
       "\n",
       "                                           embedding  \n",
       "0  [-0.08473156, 0.0026886375, -0.012588201, 0.03...  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I really like this lecture!</td>\n",
       "      <td>[-0.08473156, 0.0026886375, -0.012588201, 0.03...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 45
  },
  {
   "cell_type": "markdown",
   "id": "92e4ade64327479a",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "# But first..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1efe11323e9bd312",
   "metadata": {
    "editable": true,
    "jp-MarkdownHeadingCollapsed": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "### Select different sentence-transformer embedding models\n",
    "* https://huggingface.co/models?pipeline_tag=sentence-similarity\n",
    "\n",
    "All generated embeddings are based on [sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2](https://huggingface.co/sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2) <br>\n",
    "Maybe give a smaller model also a try: [all-MiniLM-L6-v2](https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2)\n",
    "\n",
    "### Training\n",
    "* How could a training look like?\n",
    "* Which kind of data is necessary therefore?\n",
    "* Differences between sparse and dense models in terms of training?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eee13a77a5d1c07",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "### Interesting Tasks\n",
    "* Find other promising embedding models (sparse and dense) and try them out\n",
    "    * What about Doc2Vec, word2vec, bag-of-words etc [here](https://radimrehurek.com/gensim/auto_examples/tutorials/run_doc2vec_lee.html)\n",
    "* Calculate the embedding similarities like in [here](https://huggingface.co/sentence-transformers)\n",
    "    * There might be different similarity scores dependeing on the embedder (sparse vs dense)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1a1089d984f122eb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-04T11:23:27.633817Z",
     "start_time": "2025-09-04T11:23:27.627398Z"
    },
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = 0\n",
    "i"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
