{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import pandas as pd\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from tqdm import tqdm\n",
    "from models import TfIdfEmbedder, CountVectorizerEmbedder\n",
    "\n",
    "tqdm.pandas()"
   ],
   "id": "dd4d9219674d99f6"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 1. Prepare parlamint dataset",
   "id": "d6decdf1ccb108c6"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### 1.1. Load Dataset (Sentence-Wise)",
   "id": "638b2f41ee8673d1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Load parlamint dataset\n",
    "df_parlamint = pd.read_csv(\"../../datasets/parlamint/parlamint-it-is-2022.txt\", sep=\"\\t\").head(10000)\n",
    "df_parlamint_subset = df_parlamint.copy(deep=True).head(100)\n",
    "df_parlamint"
   ],
   "id": "fa1d3cb3ce5feae2"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### 1.2. Group Dataset per Utterance",
   "id": "f0f31bf3d02e9b2b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Group sentence by utterance (=Parent_ID)\n",
    "df_parlamint_grouped = (df_parlamint.groupby([\"Parent_ID\"])[\"Text\"]\n",
    "                        .apply(lambda s: \" \".join(s))\n",
    "                        .reset_index(name=\"utterance_text\"))\n",
    "print(f\"Unique utterances: {df_parlamint_grouped.shape[0]}\")\n",
    "df_parlamint_grouped"
   ],
   "id": "2531c5dfc9c6187a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "sample_utterance = df_parlamint[df_parlamint[\"Parent_ID\"] == \"ParlaMint-IS_2022-01-17-20.u1\"][\"Text\"]\n",
    "sample_utterance"
   ],
   "id": "a0256cfd2acb044a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 2. Different Text Embedding Algorithms",
   "id": "8b078ce7bcad7c15"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### 2.1. Count Vectorizer (Sparse) Embeddings",
   "id": "ddaaa1826aa6b4a6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Adding the whole parlamint dataset as vocabulary\n",
    "# cv_model = CountVectorizerEmbedder(vocabulary=df_parlamint[\"Text\"].to_list(), min_df=100, stop_words='english',\n",
    "#                                    n_gram_range=(1, 3))\n",
    "\n",
    "# Adding just the utterance sample as vocabulary\n",
    "cv_model = CountVectorizerEmbedder(vocabulary=df_parlamint_grouped[\"utterance_text\"], max_features=10,stop_words='english')"
   ],
   "id": "81beeb0082dcd92d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "cv_embeddings = cv_model.embed(sample_utterance)\n",
    "print(f\"Number features: {len(cv_model.embedding_model.get_feature_names_out())}\", cv_model.embedding_model.get_feature_names_out())\n",
    "print(f\"Shape embedding array: {cv_embeddings.toarray().shape}\")\n",
    "df_cv_output = pd.DataFrame(columns=cv_model.embedding_model.get_feature_names_out(), data=cv_embeddings.toarray())\n",
    "df_cv_output"
   ],
   "id": "5b8f5d2aa083d8b9"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### 2.2 TF-IDF (Sparse) Embeddings",
   "id": "fbe781d76f2f4556"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Adding the whole parlamint dataset as vocabulary\n",
    "# tfidf_model = TfIdfEmbedder(vocabulary=df_parlamint[\"Text\"].to_list(), min_df=100, stop_words='english')\n",
    "\n",
    "# Adding just the utterance sample as vocabulary\n",
    "tfidf_model = TfIdfEmbedder(vocabulary=df_parlamint_grouped[\"utterance_text\"], max_features=10, stop_words='english')"
   ],
   "id": "909fb6bd4ccaf14f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "tfidf_embeddings = tfidf_model.embed(sample_utterance)\n",
    "print(f\"Number features: {len(tfidf_model.embedding_model.get_feature_names_out())}\", tfidf_model.embedding_model.get_feature_names_out())\n",
    "print(f\"Shape embedding array: {tfidf_embeddings.toarray().shape}\")\n",
    "df_tfidf_output = pd.DataFrame(columns=tfidf_model.embedding_model.get_feature_names_out(), data=tfidf_embeddings.toarray())\n",
    "df_tfidf_output"
   ],
   "id": "a0f27ebc20ab2a79"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### 2.3 Sentence Transformer (Dense) Embeddings",
   "id": "c609439f66ea70fd"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "st_model_small = SentenceTransformer('all-minilm-l6-v2')",
   "id": "f94e5814729dd8d6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Encode sentence-wise\n",
    "st_embeddings = st_model_small.encode(sample_utterance)\n",
    "print(f\"Number features: {len(st_embeddings)}\")\n",
    "print(f\"Shape embedding array: {st_embeddings.shape}\")\n",
    "st_embeddings"
   ],
   "id": "cdf8d60aa08c7b40"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Encode utterance-wise\n",
    "st_embeddings_u = st_model_small.encode(\" \".join(sample_utterance))\n",
    "print(f\"Number features: {len(st_embeddings_u)}\")\n",
    "print(f\"Shape embedding array: {st_embeddings_u.shape}\")\n",
    "st_embeddings_u"
   ],
   "id": "c9d4d330a66726ff"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 3. Encode whole Parlamint Dataset",
   "id": "252d0bec249fbc1c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### 3.1 Encode with Sentence Transformer",
   "id": "8221d6aafd8b2096"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Encode utterance-wise dataset\n",
    "df_parlamint_embeddings_per_utterance = st_model_small.encode(df_parlamint_grouped[\"utterance_text\"].to_list(),\n",
    "                                                     show_progress_bar=True)\n",
    "\n",
    "# Encode sentence-wise dataset\n",
    "df_parlamint_embeddings_per_sentence = st_model_small.encode(df_parlamint[\"Text\"].to_list(), show_progress_bar=True)"
   ],
   "id": "55d21d66a803e78c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "df_parlamint_grouped[\"embedding\"] = list(df_parlamint_embeddings_per_utterance)\n",
    "df_parlamint_grouped"
   ],
   "id": "14aac519fcb2a011"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "df_parlamint[\"embedding\"] = list(df_parlamint_embeddings_per_sentence)\n",
    "df_parlamint"
   ],
   "id": "713d04a1c14713d2"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### 3.2 Save output to pickle file",
   "id": "81c99d478e4d8eb8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "df_parlamint.to_pickle(\"df_parlamint_all-MiniLM-L6-v2.pkl\")",
   "id": "ab6b4bbb4a6ab8d5"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### 3.3 Encode Dataset with TF-IDF",
   "id": "4bea53f03ccd3c65"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Adding the whole parlamint dataset as vocabulary\n",
    "tfidf_model = TfIdfEmbedder(vocabulary=df_parlamint[\"Text\"].to_list(), max_features=100, stop_words='english')\n",
    "\n",
    "# Encode sentence-wise dataset\n",
    "tfidf_embeddings_per_sentence = tfidf_model.embed(df_parlamint[\"Text\"].to_list())"
   ],
   "id": "cc29340baae73503"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "print(f\"Number features: {len(tfidf_model.embedding_model.get_feature_names_out())}\", tfidf_model.embedding_model.get_feature_names_out())\n",
    "print(f\"Shape embedding array: {tfidf_embeddings_per_sentence.toarray().shape}\")\n",
    "tfidf_embeddings_per_sentence.toarray()"
   ],
   "id": "56f661fe2a649bd9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "df_parlamint[\"embedding\"] = list(tfidf_embeddings_per_sentence.toarray())\n",
    "df_parlamint"
   ],
   "id": "bc0c51a1c73abe79"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### 3.4 Save output to pickle file",
   "id": "4201d2ed8fbb7a0a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "df_parlamint.to_pickle(\"df_parlamint_all-tfidf.pkl\")",
   "id": "53d17fa10621b197"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### 3.5 Load data from pickle file",
   "id": "efe7a550809d42d8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "df_read_parlamint = pd.read_pickle(\"<filename_path>.pkl\")",
   "id": "d6c90720a0298ffc"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 4. Calculate similarities between embeddings",
   "id": "35b454fbc0f9b9a6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "st_model_small = SentenceTransformer('all-minilm-l6-v2')"
   ],
   "id": "cd95c78c1a3269a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# 1. Example data\n",
    "sentences = [\n",
    "    \"I deposited my paycheck at the bank yesterday.\",\n",
    "    \"We had a picnic on the bank of the river.\",\n",
    "    \"The financial institution announced a new savings account plan.\",\n",
    "    \"She withdrew cash from the nearest ATM.\",\n",
    "    \"The kids played near the riverbank after school.\"\n",
    "]\n",
    "\n",
    "query = \"financial services\"\n",
    "\n",
    "# 2. Sentence Transformers embeddings\n",
    "dense_embeddings_sentences = st_model_small.encode(sentences, convert_to_tensor=False)\n",
    "dense_embeddings_query = st_model_small.encode([query], convert_to_tensor=False)\n",
    "dense_similarities = util.cos_sim(dense_embeddings_query, dense_embeddings_sentences)[0].cpu().numpy()\n",
    "\n",
    "# 3. TF-IDF embeddings\n",
    "tfidf_model = TfIdfEmbedder(vocabulary=sentences, max_features=10, stop_words='english')\n",
    "tfidf_embeddings_sentences = tfidf_model.embed(sentences)\n",
    "tfidf_embeddings_query = tfidf_model.embed([query])\n",
    "tfidf_similarities = cosine_similarity(tfidf_embeddings_query, tfidf_embeddings_sentences).flatten()\n",
    "\n",
    "# 4. Compare rankings\n",
    "df = pd.DataFrame({\n",
    "    \"sentence\": sentences,\n",
    "    \"tfidf_similarity\": tfidf_similarities,\n",
    "    \"st_similarity\": dense_similarities\n",
    "})\n",
    "# df.sort_values(by=[\"st_similarity\"], ascending=False, inplace=True)\n",
    "df"
   ],
   "id": "dd7525df4bbc0782"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 5. How to build a Simple QA System",
   "id": "ec9d838389d65710"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### 5.1 Get the Most Likely Utterance",
   "id": "fb95067c49bcec0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import numpy as np\n",
    "from sentence_transformers import util\n",
    "\n",
    "# Given question\n",
    "question = \"What is the government policy on climate change?\"\n",
    "# question = \"What about president of america?\"\n",
    "\n",
    "# 1. Embed the question\n",
    "question_embedding = st_model_small.encode(question)\n",
    "\n",
    "# 2. Compute cosine similarities\n",
    "cosine_similarities = util.cos_sim(question_embedding, df_parlamint[\"embedding\"])[0].cpu().numpy()\n",
    "\n",
    "# 3. Get the index of the most similar utterance\n",
    "most_similar_idx = int(np.argmax(cosine_similarities))\n",
    "\n",
    "# 4. Retrieve the most similar text\n",
    "most_similar_text = df_parlamint.iloc[most_similar_idx][\"Text\"]\n",
    "# most_similar_text\n",
    "print(f\"Score: {cosine_similarities[most_similar_idx]:.4f} | Utterance: {most_similar_text}\\n\")"
   ],
   "id": "24f155ca1cc419bd"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "df_parlamint[\"Text\"]",
   "id": "9e9b8e3272abea01"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### 5.2 Get the Top-K relevant Utterances",
   "id": "d9c1c3f95fbd8ec6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "question = \"What is the government policy on climate change?\"\n",
    "# question = \"America?\"\n",
    "k = 5  # choose how many results you want\n",
    "\n",
    "# 1. Embed the question\n",
    "question_embedding = st_model_small.encode(question)\n",
    "\n",
    "# 2. Compute cosine similarities\n",
    "cosine_similarities = util.cos_sim(question_embedding, df_parlamint[\"embedding\"])[0].cpu().numpy()\n",
    "\n",
    "# 3. Get indices of top-k most similar utterances\n",
    "top_k_idx = np.argsort(cosine_similarities)[::-1][:k]\n",
    "\n",
    "# 4. Retrieve the top-k utterances and their similarity scores\n",
    "for idx in top_k_idx:\n",
    "    text = df_parlamint.iloc[idx][\"Text\"]\n",
    "    score = cosine_similarities[idx]\n",
    "    print(f\"Score: {score:.4f} | Utterance: {text}\\n\")\n"
   ],
   "id": "8c9156ebb4db2f1d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "tfidf_model = TfIdfEmbedder(vocabulary=df_parlamint[\"Text\"], max_features=1000, stop_words='english')\n",
    "tfidf_embeddings_sentences = tfidf_model.embed(df_parlamint[\"Text\"].to_list())"
   ],
   "id": "9517456ac1e0a9d7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "df_parlamint[\"embedding\"] = list(tfidf_embeddings_sentences.toarray())",
   "id": "b8119764e2e7e050"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "question = \"What is the government policy on climate change?\"\n",
    "# question = \"America?\"\n",
    "k = 5  # choose how many results you want\n",
    "\n",
    "# 1. Embed the question\n",
    "#question_embedding = tfidf_model.encode(question)\n",
    "question_embedding = tfidf_model.embed([question])\n",
    "\n",
    "# 2. Compute cosine similarities\n",
    "cosine_similarities = util.cos_sim(question_embedding.toarray(), df_parlamint[\"embedding\"])[0].cpu().numpy()\n",
    "\n",
    "# 3. Get indices of top-k most similar utterances\n",
    "top_k_idx = np.argsort(cosine_similarities)[::-1][:k]\n",
    "\n",
    "# 4. Retrieve the top-k utterances and their similarity scores\n",
    "for idx in top_k_idx:\n",
    "    text = df_parlamint.iloc[idx][\"Text\"]\n",
    "    score = cosine_similarities[idx]\n",
    "    print(f\"Score: {score:.4f} | Utterance: {text}\\n\")\n"
   ],
   "id": "5596ec638297f574"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import numpy as np\n",
    "np.where(question_embedding.toarray() > 0)\n"
   ],
   "id": "e7f722eaaa629c77"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "print(f\"Number features: {len(tfidf_model.embedding_model.get_feature_names_out())}\", tfidf_model.embedding_model.get_feature_names_out())\n",
    "print(f\"Shape embedding array: {tfidf_embeddings.toarray().shape}\")\n",
    "df_tfidf_output = pd.DataFrame(columns=tfidf_model.embedding_model.get_feature_names_out(), data=tfidf_embeddings.toarray())"
   ],
   "id": "78f65d59cfb4ca2f"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
